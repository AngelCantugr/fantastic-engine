# ðŸš€ Getting Started: Data + AI Engineering

**Read Time:** 10 minutes
**Difficulty:** Beginner
**Prerequisites:** Basic Python, SQL, Docker knowledge

---

## ðŸŽ¯ What You'll Learn (in 10 minutes)

```mermaid
graph LR
    A[ðŸ“– Concepts] --> B[ðŸ› ï¸ Setup]
    B --> C[ðŸŽ® First Project]
    C --> D[âœ… Validation]

    style A fill:#ff00ff,stroke:#00ffff
    style B fill:#00ffff,stroke:#ff00ff
    style C fill:#00ff00,stroke:#ff00ff
    style D fill:#ffff00,stroke:#ff00ff
```

1. **Core Concepts** (2 min) - What is Data + AI Engineering?
2. **Environment Setup** (5 min) - Install tools
3. **First Use Case** (3 min) - Run AI Data Quality Validator

---

## ðŸ“– Part 1: Core Concepts (2 minutes)

### What is Data Engineering?

```mermaid
flowchart LR
    A[Raw Data<br/>ðŸ’¾] --> B[Extract<br/>ðŸ“¥]
    B --> C[Transform<br/>âš™ï¸]
    C --> D[Load<br/>ðŸ“¤]
    D --> E[Clean Data<br/>âœ¨]

    style A fill:#ff00ff,stroke:#00ffff
    style E fill:#00ff00,stroke:#ff00ff
```

**In simple terms:** Moving and cleaning data so it's ready to use.

**Examples:**
- Collecting user clicks from website â†’ Database
- Converting CSVs â†’ Organized database tables
- Combining data from 10 different sources

---

### What is AI Engineering?

```mermaid
flowchart LR
    A[Clean Data<br/>âœ¨] --> B[Train Model<br/>ðŸ§ ]
    B --> C[Deploy Model<br/>ðŸš€]
    C --> D[Make Predictions<br/>ðŸ”®]

    style A fill:#00ff00,stroke:#ff00ff
    style B fill:#ffff00,stroke:#ff00ff
    style C fill:#ff69b4,stroke:#00ffff
    style D fill:#9370db,stroke:#00ffff
```

**In simple terms:** Building and running AI models in production.

**Examples:**
- Training a model to detect spam
- Deploying model to classify 1M emails/day
- Monitoring model accuracy over time

---

### How They Converge ðŸ¤

```mermaid
graph TB
    subgraph "Traditional (Separate)"
        A1[Data Engineer] -.-> A2[AI Engineer]
        A2 -.-> A3[DevOps]
    end

    subgraph "Modern (Convergence)"
        B1[Data + AI Engineer<br/>âš¡ You!]
        B1 --> B2[Pipelines]
        B1 --> B3[Models]
        B1 --> B4[Production]
    end

    style B1 fill:#ff00ff,stroke:#00ffff
    style B2 fill:#00ffff,stroke:#ff00ff
    style B3 fill:#00ff00,stroke:#ff00ff
    style B4 fill:#ffff00,stroke:#ff00ff
```

**Why this matters:**
- âœ… Faster iteration (no handoffs)
- âœ… Better models (you control the data)
- âœ… Higher pay (rare skillset)

---

## ðŸ› ï¸ Part 2: Environment Setup (5 minutes)

### Checklist

- [ ] Install Docker
- [ ] Install Python 3.11+
- [ ] Install uv (Python package manager)
- [ ] Clone repository
- [ ] Verify setup

---

### Step-by-Step Setup

#### 1. Install Docker (1 min)

```bash
# Mac
brew install --cask docker

# Linux
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Verify
docker --version
# Output: Docker version 24.x.x
```

#### 2. Install Python + uv (1 min)

```bash
# Install uv (fast Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Verify
uv --version
python3 --version
```

#### 3. Navigate to Project (30 sec)

```bash
cd /home/user/fantastic-engine/projects/data-ai-engineering
```

#### 4. Test Setup (2 min)

```bash
# Quick test: Run AI Data Quality Validator
cd use-cases/04-data-quality-ai

# Create virtual environment
uv venv --python 3.11
source .venv/bin/activate

# Install minimal dependencies
uv pip install pandas click rich loguru

# Test import
python -c "import pandas; print('âœ… Setup successful!')"
```

âœ… If you see "Setup successful!" â†’ Continue!
âŒ If you see errors â†’ Check Python version

---

## ðŸŽ® Part 3: Your First Project (3 minutes)

Let's run the **AI-Powered Data Quality Validator**!

### What It Does

```mermaid
flowchart LR
    A[ðŸ“Š Your Data] --> B[ðŸ¤– AI Validator]
    B --> C1[âœ… Quality Report]
    B --> C2[ðŸ’¡ Suggestions]
    B --> C3[ðŸ“ Auto Docs]

    style A fill:#ff00ff,stroke:#00ffff
    style B fill:#00ff00,stroke:#ff00ff
```

**In 30 seconds:** AI reads your data, finds problems, explains them in English, and suggests fixes.

---

### Run It!

```bash
# 1. Create sample dataset (10 seconds)
cat > sample_data.csv << 'EOF'
age,income,score
25,50000,85
30,-5000,92
35,75000,88
40,60000,150
EOF

# 2. Run validator (20 seconds)
python run_validator.py \
  --dataset sample_data.csv \
  --quick \
  --llm-provider none

# Output:
# ðŸ” AI-Powered Data Quality Validator
# âœ“ Loading dataset...
# âœ“ Running validation...
# âœ… Validation PASSED
```

### What Just Happened?

1. âœ… Validator loaded your CSV
2. âœ… Checked for common issues (negatives, outliers)
3. âœ… Generated report

**Next:** Try with a real dataset (NYC Taxi data)!

---

## âœ… Part 4: Validation (30 seconds)

Quick quiz to check understanding:

### Question 1
**What does Data Engineering do?**
- A) Train AI models
- B) Move and clean data âœ…
- C) Build websites

### Question 2
**What's the benefit of Data + AI convergence?**
- A) Slower development
- B) Faster iteration, better models âœ…
- C) More meetings

### Question 3
**What did the validator check in our example?**
- A) Spelling errors
- B) Data quality issues (negative values, outliers) âœ…
- C) Code bugs

---

## ðŸŽ¯ What's Next?

```mermaid
graph LR
    A[âœ… Getting Started] --> B[ðŸ“š Learn Concepts]
    B --> C[ðŸ—ï¸ Build Use Cases]
    C --> D[ðŸš€ Production Deploy]

    style A fill:#00ff00,stroke:#ff00ff
    style B fill:#ffff00,stroke:#ff00ff
    style C fill:#ff69b4,stroke:#00ffff
    style D fill:#9370db,stroke:#00ffff
```

**Recommended Path:**

### Week 1: Foundations
- [ ] Read: [02-core-concepts.md](02-core-concepts.md) - Deep dive into architecture patterns
- [ ] Practice: Use Case #3 (AI Data Quality) - Full tutorial
- [ ] Time: 2-3 hours

### Week 2: Production ML
- [ ] Read: [03-mlops-fundamentals.md](03-mlops-fundamentals.md) - Feature stores, model registry
- [ ] Practice: Use Case #2 (MLOps Pipeline) - Build FTI pipeline
- [ ] Time: 4-5 hours

### Week 3: Real-Time Systems
- [ ] Read: [04-streaming-systems.md](04-streaming-systems.md) - Kafka, Spark Streaming
- [ ] Practice: Use Case #1 (Real-time Sentiment) - Streaming pipeline
- [ ] Time: 4-5 hours

### Week 4: Advanced Topics
- [ ] Read: [05-production-deployment.md](05-production-deployment.md) - Kubernetes, monitoring
- [ ] Practice: Deploy to AWS/GCP
- [ ] Time: 3-4 hours

**Total Time:** ~15 hours over 4 weeks = **1 hour/day**

---

## ðŸ†˜ Troubleshooting

### Issue: Docker not working
```bash
# Check Docker is running
docker ps

# If not:
# Mac: Open Docker Desktop app
# Linux: sudo systemctl start docker
```

### Issue: Python version wrong
```bash
# Install Python 3.11 with uv
uv python install 3.11

# Create environment with specific version
uv venv --python 3.11
```

### Issue: Import errors
```bash
# Make sure venv is activated
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows

# Reinstall dependencies
uv pip install -r requirements.txt
```

---

## ðŸ“š Additional Resources

### Quick References
- [Cheat Sheet](../architecture/cheat-sheet.md) - All commands in one place
- [FAQ](../architecture/faq.md) - Common questions

### Deep Dives (when ready)
- [Architecture Patterns](../architecture/patterns.md)
- [Best Practices](../architecture/best-practices.md)

---

## ðŸŽ‰ Congratulations!

You've completed the getting started guide!

**You now know:**
- âœ… What Data + AI Engineering is
- âœ… How to set up your environment
- âœ… How to run your first use case

**Next step:** [Core Concepts Guide â†’](02-core-concepts.md)

---

**Time spent:** ~10 minutes
**Progress:** â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 10% of full project

Keep going! ðŸš€
